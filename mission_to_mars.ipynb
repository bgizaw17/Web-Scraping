{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mission to mars\n",
    "# scraping data from multiple websites into MongoDB, \n",
    "# and then send that data to a Flask web server\n",
    "# and then to a website to view the data\n",
    "\n",
    "# a: scraping dependencies\n",
    "print(\"Importing dependencies for scraper...\")\n",
    "import time\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "from selenium import webdriver\n",
    "executable_path = {\"executable_path\": \"/python_chrome_driver/drivers\"}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=False)\n",
    "print(\"Importing dependencies for scraper...done\")# ====================================================================\n",
    "print(\"====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b: Scrape the NASA Mars News Site and collect the latest News Title and Paragraph Text.\n",
    "# Assign the text to variables that you can reference later.\n",
    "print(\"Now scraping NASA Mars New Site\")\n",
    "print(\"URL to scrape:\")\n",
    "print(url_nasa_mars_news)\n",
    "url_nasa_mars_news = \"https://mars.nasa.gov/news/\"\n",
    "print(\"Now opening site with browser\")\n",
    "browser.visit(url_nasa_mars_news)\n",
    "# wait a few seconds to allow your computer to open chrome driver\n",
    "time.sleep(3)\n",
    "print(\"Now opening site with browser...done\")\n",
    "\n",
    "# import page into bs4\n",
    "print(\"Now importing page\")\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "# wait a few seconds to allow your computer to import the page\n",
    "time.sleep(3)\n",
    "\n",
    "# get the newest article with title and date\n",
    "print(\"Identifying newest article...\")\n",
    "newest_article = soup.find(\"div\", class_=\"list_text\")\n",
    "newest_paragraph = newest_article.find(\"div\", class_=\"article_teaser_body\").text\n",
    "newest_title = newest_article.find(\"div\", class_=\"content_title\").text\n",
    "newest_date = newest_article.find(\"div\", class_=\"list_date\").text\n",
    "print(\"Identifying newest article...\")\n",
    "print(newest_date)\n",
    "print(newest_title)\n",
    "print(newest_paragraph)\n",
    "print(\"Identifying newest article...done\")\n",
    "# ====================================================================\n",
    "print(\"====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c: JPL Mars Space Images - Featured Image\n",
    "url_jpl_mars_space_images = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "print(\"Now scraping NASA JPL Mars Space Images for Featured Image\")\n",
    "print(\"URL to scrape:\")\n",
    "print(url_jpl_mars_space_images)\n",
    "\n",
    "print(\"Now opening site with browser\")\n",
    "browser.visit(url_jpl_mars_space_images)\n",
    "\n",
    "# wait a few seconds to allow your computer to open the page\n",
    "time.sleep(3)\n",
    "print(\"Now opening site with browser...done\")\n",
    "\n",
    "# import page into bs4\n",
    "print(\"Now importing page\")\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "print(\"Now identifying featured image\")\n",
    "image = soup.find(\"img\", class_=\"thumb\")[\"src\"]\n",
    "img_url = \"https://jpl.nasa.gov\"+image\n",
    "featured_image_url = img_url\n",
    "print(\"Featured Image URL:\")\n",
    "print(featured_image_url)\n",
    "\n",
    "print(\"Now downloading featured image\")\n",
    "import requests\n",
    "import shutil\n",
    "response = requests.get(img_url, stream=True)\n",
    "with open('img.jpg', 'wb') as out_file:\n",
    "    shutil.copyfileobj(response.raw, out_file)\n",
    "# wait a few seconds to allow your computer to get the image\n",
    "time.sleep(3)\n",
    "print(\"Now downloading featured image...done\")\n",
    "print(\"Now previewing featured image\")\n",
    "from IPython.display import Image\n",
    "Image(url='img.jpg')\n",
    "# wait a few seconds to allow your computer to show the image\n",
    "time.sleep(3)\n",
    "print(\"Now previewing featured image...done\")\n",
    "# ====================================================================\n",
    "print(\"====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d: Mars Weather\n",
    "print(\"Now scraping Mars Weather from Twitter\")\n",
    "# Visit the Mars Weather twitter account using tweepy with twitter api keys\n",
    "print(\"Now loading Twitter handler\")\n",
    "import tweepy\n",
    "from key_vault import (consumer_key, \n",
    "                    consumer_secret, \n",
    "                    access_token, \n",
    "                    access_token_secret)\n",
    "print(\"Now loading Twitter handler...done\")\n",
    "print(\"Now authenticating Twitter handler with twitter API\")\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "print(\"Now authenticating Twitter handler with twitter API...done\")\n",
    "\n",
    "# scrape the latest Mars weather tweet from the page. \n",
    "print(\"Now scraping the latest Mars weather tweet from their twitter page\")\n",
    "target_user = \"marswxreport\"\n",
    "print(\"Twitter user id:\")\n",
    "print(target_user)\n",
    "print(\"Now Identifying twitter user's tweets\")\n",
    "full_tweet = api.user_timeline(target_user , count = 1)\n",
    "\n",
    "# Save the tweet as a variable called 'mars_weather'\n",
    "mars_weather = full_tweet[0]['text']\n",
    "print(\"Now previewing twitter user's latest Tweet:\")\n",
    "print(mars_weather)\n",
    "print(\"Now previewing twitter user's latest Tweet...done\")\n",
    "# ====================================================================\n",
    "print(\"====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e: # Visit the Mars Facts webpage\n",
    "print(\"Now scraping the Mars Facts webpage\")\n",
    "print(\"URL to scrape:\")\n",
    "url_mars_facts = 'http://space-facts.com/mars/'\n",
    "print(url_mars_facts)\n",
    "\n",
    "print(\"Now opening site with browser\")\n",
    "browser.visit(url_mars_facts)\n",
    "\n",
    "\n",
    "# use Pandas to scrape the table containing facts about the planet\n",
    "# include Diameter, Mass, etc.\n",
    "import pandas as pd \n",
    "print(\"Now importing site\")\n",
    "grab = pd.read_html(url_mars_facts)\n",
    "mars_facts_data = pd.DataFrame(grab[0])\n",
    "mars_facts_data.columns = ['Mars','Data']\n",
    "mars_facts_table = mars_facts_data.set_index(\"Mars\")\n",
    "\n",
    "# Use Pandas to convert the data to an HTML table string.\n",
    "mars_facts_data_clean = mars_facts_table.to_html(classes='marsdata')\n",
    "mars_facts_data_clean = marsdata.replace('\\n', ' ')\n",
    "print(mars_facts_data_clean)\n",
    "# ====================================================================\n",
    "print(\"====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f: Mars Hemispheres\n",
    "print(\"Now scraping USGS Astrogeology site for pictures of Mars' hemispheres\")\n",
    "print(\"URL to scrape:\")\n",
    "url_USGS_astrogeology = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "print(url_USGS_astrogeology)\n",
    "print(\"Now opening site with browser\")\n",
    "browser.visit(url_USGS_astrogeology)\n",
    "html = browser.html\n",
    "print(\"Now importing site\")\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "# Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name.\n",
    "# Use a Python dictionary to store the data using the keys img_url and title.\n",
    "# Append the dictionary with the image url string and the hemisphere title to a list. \n",
    "# This list will contain one dictionary for each hemisphere.\n",
    "\n",
    "# loop through the 4 images and load them into a dictionary\n",
    "mars_hemispheres = []\n",
    "print(\"Obtaining image urls\")\n",
    "for i in range (4):\n",
    "    # wait a few seconds to load each image\n",
    "    time.sleep(5)\n",
    "    images = browser.find_by_tag('h3')\n",
    "    images[i].click()\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    partial = soup.find(\"img\", class_=\"wide-image\")[\"src\"]\n",
    "    img_title = soup.find(\"h2\",class_=\"title\").text\n",
    "    img_url = 'https://astrogeology.usgs.gov'+ partial\n",
    "    dictionary={\"title\":img_title,\"img_url\":img_url}\n",
    "    mars_hemispheres.append(dictionary)\n",
    "    browser.back()\n",
    "print(mars_hemispheres)\n",
    "print(\"Obtaining image urls...done\")\n",
    "# ====================================================================\n",
    "print(\"====================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB with Flask templating\n",
    "# to create a new HTML page that \n",
    "# displays all of the information \n",
    "# that was scraped from the URLs above\n",
    "\n",
    "# Create a dictionary for all of the scraped data\n",
    "\n",
    "print(\"Now combining all of the scraped data...\")\n",
    "mars_data_master = {}\n",
    "mars_data_master[\"news_date\"] = newest_date\n",
    "mars_data_master[\"news_title\"] = newest_title\n",
    "mars_data_master[\"summary\"] = newest_paragraph\n",
    "mars_data_master[\"featured_image_url\"] = featured_image_url\n",
    "mars_data_master[\"mars_facts_data_clean\"] = mars_facts_data_clean\n",
    "mars_data_master[\"mars_weather\"] = mars_weather\n",
    "mars_data_master[\"mars_hemispheres\"] = mars_hemispheres\n",
    "print(\"Now combining all of the scraped data...done\")\n",
    "print(\"previewing master data:\")\n",
    "print(mars_data_master)\n",
    "\n",
    "\n",
    "# get flask server and MongoDB interface\n",
    "print(\"Now starting web server\")\n",
    "from flask import Flask, render_template, jsonify, redirect\n",
    "from flask_pymongo import PyMongo\n",
    "\n",
    "# create flask app instance\n",
    "app = Flask(__name__)\n",
    "mongo = PyMongo(app)\n",
    "\n",
    "#  create route for index.html template\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    mars = mongo.db.mars.find_one()\n",
    "    return render_template(\"index.html\", mars=mars)\n",
    "\n",
    "#  create route for scraped data\n",
    "@app.route(\"/scrape\")\n",
    "def scrape():\n",
    "    mars = mongo.db.mars\n",
    "    mars_data_master = mars_data_master.scrape()\n",
    "    mars.update(\n",
    "        {},\n",
    "        mars_data_master,\n",
    "        upsert=True\n",
    "    )\n",
    "    return redirect(\"http://localhost:5000/\", code=302)\n",
    "\n",
    "# start flask server\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n",
    "# ====================================================================  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
